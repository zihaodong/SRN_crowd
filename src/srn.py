"""
Network defination for Scale-Recursive Network with point supervision.

Network is adopted across three different scales in the coarse-to-fine strategy; each encoder/decoder module takes a 
sequence of images generated by the previous module as inputs, and a set of corresponding density maps and point maps 
are produced at different scales. 

For more info on the architecture please refer this paper:
[1] Zihao Dong, Ruixun Zhang, and Xiuli Shao. Scale-Recursive Network with Point Supervision for Crowd Scene[J]. 
    Neurocomputing, 2020, 384: 314-324.

@author: Zihao Dong
"""

import tensorflow as tf
import numpy as np
import tensorflow.contrib.slim as slim
from src.BasicConvLSTMCell import *

# SRN Network
def generator(inputs, reuse=False, scope='SRN_net'):

    n_levels = 3
    n, h, w, c = inputs.get_shape().as_list()
    with tf.variable_scope('LSTM'):
        cell = BasicConvLSTMCell([h / 4, w / 4], [3, 3], 128)
        rnn_state = cell.zero_state(batch_size=4, dtype=tf.float32)

    x_unwrap = []
    x_unwrap1 = []

    with tf.variable_scope(scope, reuse=reuse):
        with slim.arg_scope([slim.conv2d, slim.conv2d_transpose],
                            activation_fn=tf.nn.relu, 
                            padding='SAME',
                            #dilate=1,
                            # normalizer_fn=slim.batch_norm,
                            normalizer_fn=None,
                            weights_initializer=tf.truncated_normal_initializer(stddev=0.02),
                            # weights_initializer=tf.contrib.layers.xavier_initializer(uniform=True),
                            biases_initializer=tf.constant_initializer(0.0)):

            
            inp_pred = inputs
            for i in range(n_levels):
                scale = 0.5 ** (n_levels - i - 1)
                hi = int(round(h * scale))
                wi = int(round(w * scale))
                inp_blur = tf.image.resize_images(inputs, [hi, wi], method=0)
                inp_pred = tf.stop_gradient(tf.image.resize_images(inp_pred, [hi, wi], method=0))
                inp_all = tf.concat([inp_blur, inp_pred], axis=3, name='inp')

                rnn_state = tf.image.resize_images(rnn_state, [hi // 4, wi // 4], method=0)

                # Encoder
                conv1_1 = slim.conv2d(inp_all, 32, [5, 5], scope='enc1_1')
                conv1_2 = slim.conv2d(conv1_1, 32, [5, 5], scope='enc1_2')
                conv1_3 = slim.conv2d(conv1_2, 32, [5, 5], scope='enc1_3')
                conv1_4 = slim.conv2d(conv1_3, 32, [5, 5], scope='enc1_4')

                ## stack pool
                pool2_1 = slim.max_pool2d(conv1_4, [2, 2],stride=2,padding='SAME',scope='pool2_1')
                pool2_2 = slim.max_pool2d(pool2_1, [2, 2],stride=1,padding='SAME',scope='pool2_2')
                pool2_3 = slim.max_pool2d(pool2_2, [3, 3],stride=1,padding='SAME',scope='pool2_3')
                conv2_1 = (pool2_1+pool2_2+pool2_3)/3.0

                conv2_2 = slim.conv2d(conv2_1, 64, [5, 5], scope='enc2_2')
                conv2_3 = slim.conv2d(conv2_2, 64, [5, 5], scope='enc2_3')
                conv2_4 = slim.conv2d(conv2_3, 64, [5, 5], scope='enc2_4')
               
                # stack pool
                pool3_1 = slim.max_pool2d(conv2_4, [2, 2],stride=2,padding='SAME',scope='pool3_1')
                pool3_2 = slim.max_pool2d(pool3_1, [2, 2],stride=1,padding='SAME',scope='pool3_2')
                pool3_3 = slim.max_pool2d(pool3_2, [3, 3],stride=1,padding='SAME',scope='pool3_3')
                conv3_1 = (pool3_1+pool3_2+pool3_3)/3.0

                conv3_2 = slim.conv2d(conv3_1, 128, [5, 5], scope='enc3_2')
                conv3_3 = slim.conv2d(conv3_2, 128, [5, 5], scope='enc3_3')    
                conv3_4 = slim.conv2d(conv3_3, 128, [5, 5], scope='enc3_4')  

                # deconv3_4 = conv3_4
                deconv3_4, rnn_state = cell(conv3_4, rnn_state)

                # Decoder: Density Map Regression
                deconv3_3 = slim.conv2d(deconv3_4, 128, [5, 5], scope='dec3_3')
                deconv3_2 = slim.conv2d(deconv3_3, 128, [5, 5], scope='dec3_2')
                deconv3_1 = slim.conv2d(deconv3_2, 128, [5, 5], scope='dec3_1')

                deconv2_4 = slim.conv2d_transpose(deconv3_1, 64, [4, 4], stride=2,scope='dec2_4')
                cat2 = deconv2_4 + conv2_4

                deconv2_3 = slim.conv2d(cat2, 64, [5, 5], scope='dec2_3')
                deconv2_2 = slim.conv2d(deconv2_3, 64, [5, 5], scope='dec2_2')
                deconv2_1 = slim.conv2d(deconv2_2, 64, [5, 5], scope='dec2_1')  

                deconv1_4 = slim.conv2d_transpose(deconv2_1, 32, [4, 4], stride=2, scope='dec1_4')
                cat1 = deconv1_4 + conv1_4

                deconv1_3 = slim.conv2d(cat1, 32, [5, 5], scope='dec1_3')
                deconv1_2 = slim.conv2d(deconv1_3, 32, [5, 5], scope='dec1_2')
                deconv1_1 = slim.conv2d(deconv1_2, 32, [5, 5], scope='dec1_1')

                inp_pred =  slim.conv2d(deconv1_1, 3, [5, 5],activation_fn=None, scope='dec1_0')

                # Decoder: Point Map Segmentation
                deconv13_3 = slim.conv2d(deconv3_4, 128, [5, 5], scope='dec13_3')
                deconv13_2 = slim.conv2d(deconv13_3, 128, [5, 5], scope='dec13_2')
                deconv13_1 = slim.conv2d(deconv13_2, 128, [5, 5], scope='dec13_1')
                deconv12_4 = slim.conv2d_transpose(deconv13_1, 64, [4, 4], stride=2,scope='dec12_4')
                cat12 = deconv12_4 + conv2_4
      
                deconv12_3 = slim.conv2d(cat12, 64, [5, 5], scope='dec12_3')
                deconv12_2 = slim.conv2d(deconv12_3, 64, [5, 5], scope='dec12_2')
                deconv12_1 = slim.conv2d(deconv12_2, 64, [5, 5], scope='dec12_1')  
                deconv11_4 = slim.conv2d_transpose(deconv12_1, 32, [4, 4], stride=2, scope='dec11_4')
                cat11 = deconv11_4 + conv1_4
 
                deconv11_3 = slim.conv2d(cat11, 32, [5, 5], scope='dec11_3')
                deconv11_2 = slim.conv2d(deconv11_3, 32, [5, 5], scope='dec11_2')
                deconv11_1 = slim.conv2d(deconv11_2, 32, [5, 5], scope='dec11_1')

                encode_output =  slim.conv2d(deconv11_1, 3, [5, 5],activation_fn=None, scope='dec11_0')
                encode_output = tf.sigmoid(encode_output)
 
                # The fusion results: Density Map and Point Map  
                inp_pred = encode_output * inp_pred
                inp_pred = slim.conv2d(inp_pred, 3, [5, 5],activation_fn=None, scope='dedsafeafdc1_0')

                if i >= 0:
                    x_unwrap.append(inp_pred)
                    x_unwrap1.append(encode_output)
                if i == 0:
                    tf.get_variable_scope().reuse_variables()

        return x_unwrap, x_unwrap1



def build(input_tensor, norm = False):
    """
    Builds the SRN with Point Supervision.
    :param input_tensor: Input tensor image to the network.
    :return: estimated density map tensor.
    """
    tf.summary.image('input', input_tensor, 1)
    if norm:
        input_tensor = tf.cast(input_tensor, tf.float32) * (1. / 255) - 0.5
    full_net = generator(input_tensor, reuse=False, scope='SRN_net')
    return full_net


# Testing the data flow of the network with some random inputs.
if __name__ == "__main__":
    x = tf.placeholder(tf.float32, [1, 200, 300, 3])
    net = build(x)
    init = tf.initialize_all_variables()
    sess = tf.Session()
    sess.run(init)
    d_map = sess.run(net,feed_dict={x:255*np.ones(shape=(1,200,300,3), dtype=np.float32)})
    prediction = np.asarray(d_map)
    prediction = np.squeeze(prediction, axis=0)
    prediction = np.squeeze(prediction, axis=2)
